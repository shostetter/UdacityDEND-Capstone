{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Immigration by City Data Lake\n",
    "### Data Engineering Capstone Project\n",
    "\n",
    "#### Project Summary\n",
    "This notebook extracts data from a number of sources and generates a data model to analyze international arrival data to different cities throughout the US. The data is modeled in a star schema and the fact table is written to parquet files. This process will facilitate analytics on the data from the different sources, including immigration details from the I94, temperature data, demmographics from US cities, and airports.  \n",
    "\n",
    "The project follows the follow steps:\n",
    "* Step 1: Scope the Project and Gather Data\n",
    "* Step 2: Explore and Assess the Data\n",
    "* Step 3: Define the Data Model\n",
    "* Step 4: Run ETL to Model the Data\n",
    "* Step 5: Complete Project Write Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do all imports and installs here\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from udfs import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dfine/configure Spark session\n",
    "spark = SparkSession.builder.\\\n",
    "config(\"spark.jars.packages\",\"saurfang:spark-sas7bdat:2.0.0-s_2.11\")\\\n",
    ".enableHiveSupport().getOrCreate()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Scope the Project and Gather Data\n",
    "\n",
    "#### Scope \n",
    "The fact and dimension tables used in this project are derived from four data sources. The fact table is designed for analyzing international arrival data by city and month for U.S. airport arrivals. This notebook is designed to build a data lake, rather than a data warehouse. This allows greater flexibility in analysis while minimizing the transformations needed to process the data. \n",
    "\n",
    "This project uses Python and Apache Spark to process this data. \n",
    "\n",
    "#### Data sources for the project: \n",
    "\n",
    " 1. I94 Immigration Data: comes from the U.S. National Tourism and Trade Office and includes details on incoming international arrivals. The data includes information on country of origin, visa type, age, and port of entry [link](https://travel.trade.gov/research/reports/i94/historical/2016.html)\n",
    " 1. U.S. City Demographic Data: comes from OpenSoft originally from the U.S. Census Bureau's 2015 American Community Survey and includes data by city, state, age, gender, and foreign-born population [link](https://public.opendatasoft.com/explore/dataset/us-cities-demographics/export/)\n",
    " 1. Airport Code Table: comes from datahub.io and includes airport codes and corresponding cities [link](https://datahub.io/core/airport-codes#data)\n",
    " 1. World Temperature Data: comes from Kaggle and includes temperature data in the U.S. since from 1850 to 2013 [link](https://www.kaggle.com/berkeleyearth/climate-change-earth-surface-temperature-data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the data here\n",
    "demographics=spark.read.format(\"csv\").option(\"delimiter\", \";\").option(\"header\", \"true\").load(\"us-cities-demographics.csv\")\n",
    "airport=spark.read.format(\"csv\").option(\"delimiter\", \",\").option(\"header\", \"true\").load(\"airport-codes_csv.csv\")\n",
    "temperature=spark.read.format(\"csv\").option(\"delimiter\", \",\").option(\"header\", \"true\").load(\"GlobalLandTemperaturesByCity.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [00:00<00:00, 77803.28it/s]\n"
     ]
    }
   ],
   "source": [
    "to_load = input\n",
    "# load all of 2016 immigration data (June has an extra 6 columns)\n",
    "june = 'i94_jun16_sub'\n",
    "immigration = spark.read.format('com.github.saurfang.sas.spark').load('../../data/18-83510-I94-Data-2016/{}.sas7bdat'.format(june))\n",
    "immigration = immigration.drop('validres','delete_days','delete_mexl','delete_dup','delete_recdup','delete_visa')\n",
    "\n",
    "other_months = ['i94_jan16_sub','i94_feb16_sub','i94_mar16_sub','i94_apr16_sub','i94_may16_sub',\n",
    "          'i94_jul16_sub','i94_aug16_sub','i94_sep16_sub','i94_oct16_sub','i94_nov16_sub',\n",
    "          'i94_dec16_sub']\n",
    "for m in tqdm(other_months):\n",
    "    # Comment out next 2 lines for faster testing \n",
    "#     tmp = spark.read.format('com.github.saurfang.sas.spark').load('../../data/18-83510-I94-Data-2016/{}.sas7bdat'.format(m))\n",
    "#     immigration = immigration.union(tmp)\n",
    "    pass "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Explore and Assess the Data\n",
    "#### Explore the Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0-------------------\n",
      " cicid    | 4.0             \n",
      " i94yr    | 2016.0          \n",
      " i94mon   | 6.0             \n",
      " i94cit   | 135.0           \n",
      " i94res   | 135.0           \n",
      " i94port  | XXX             \n",
      " arrdate  | 20612.0         \n",
      " i94mode  | null            \n",
      " i94addr  | null            \n",
      " depdate  | null            \n",
      " i94bir   | 59.0            \n",
      " i94visa  | 2.0             \n",
      " count    | 1.0             \n",
      " dtadfile | null            \n",
      " visapost | null            \n",
      " occup    | null            \n",
      " entdepa  | Z               \n",
      " entdepd  | null            \n",
      " entdepu  | U               \n",
      " matflag  | null            \n",
      " biryear  | 1957.0          \n",
      " dtaddto  | 10032016        \n",
      " gender   | null            \n",
      " insnum   | null            \n",
      " airline  | null            \n",
      " admnum   | 1.4938462027E10 \n",
      " fltno    | null            \n",
      " visatype | WT              \n",
      "only showing top 1 row\n",
      "\n",
      "-RECORD 0------------------------------------\n",
      " City                   | Silver Spring      \n",
      " State                  | Maryland           \n",
      " Median Age             | 33.8               \n",
      " Male Population        | 40601              \n",
      " Female Population      | 41862              \n",
      " Total Population       | 82463              \n",
      " Number of Veterans     | 1562               \n",
      " Foreign-born           | 30908              \n",
      " Average Household Size | 2.6                \n",
      " State Code             | MD                 \n",
      " Race                   | Hispanic or Latino \n",
      " Count                  | 25924              \n",
      "only showing top 1 row\n",
      "\n",
      "-RECORD 0----------------------------\n",
      " ident        | 00A                  \n",
      " type         | heliport             \n",
      " name         | Total Rf Heliport    \n",
      " elevation_ft | 11                   \n",
      " continent    | NA                   \n",
      " iso_country  | US                   \n",
      " iso_region   | US-PA                \n",
      " municipality | Bensalem             \n",
      " gps_code     | 00A                  \n",
      " iata_code    | null                 \n",
      " local_code   | 00A                  \n",
      " coordinates  | -74.9336013793945... \n",
      "only showing top 1 row\n",
      "\n",
      "-RECORD 0-------------------------------------------\n",
      " dt                            | 1743-11-01         \n",
      " AverageTemperature            | 6.068              \n",
      " AverageTemperatureUncertainty | 1.7369999999999999 \n",
      " City                          | Århus              \n",
      " Country                       | Denmark            \n",
      " Latitude                      | 57.05N             \n",
      " Longitude                     | 10.33E             \n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "immigration.show(1, vertical=True)\n",
    "demographics.show(1, vertical=True)\n",
    "airport.show(1, vertical=True)\n",
    "temperature.show(1, vertical=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cleaning Steps\n",
    "Each data set will be cleaned and processed individually. \n",
    " 1. Cleaning Temperature data\n",
    "     1. Parse date to add year and month columns\n",
    "     1. Filter for U.S. cities \n",
    "     1. Add average temperature by month column \n",
    "     1. Add average temperature uncertainty column \n",
    "     1. Drop duplicates\n",
    " 1. Cleaning Airport data\n",
    "     1. Filter for U.S. locations \n",
    "     1. Transform city name to upper case for easier joins\n",
    "     1. Filter for airports \n",
    "     1. Parse region code for state code value \n",
    "     1. Drop duplicates\n",
    " 1. Cleaning up demographic data \n",
    "     1. Calculate percentages for gender and foreign-born populations \n",
    "     1. Format median age as float and city as upper case \n",
    "     1. Rename fields \n",
    "     1. Drop duplicates\n",
    " 1. Cleaning Immigration data\n",
    "     1. Filter for arrivals by air, non-null origin country code, non-null destination code\n",
    "     1. Limit table to year, month, origin country, destination city, destination state, visa type, age, and gender fields\n",
    "     1. Populate destination city value from destination code\n",
    "     1. Populate origin country value from origin country code\n",
    "     1. Aggregate table by yea, month, destination state, destination city, visa type, age gender, and country of origin \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean temp\n",
    "# add year and month columns \n",
    "temperature = temperature.withColumn(\"year\",year(temperature[\"dt\"]))\\\n",
    ".withColumn(\"month\",month(temperature[\"dt\"]))\\\n",
    "# only need US temps\n",
    "temperature=temperature.filter(temperature[\"country\"]==\"United States\")\\\n",
    ".withColumn('City', upper(col('City')))\n",
    "\n",
    "# Avg by city / month\n",
    "temperature_avg=temperature.groupBy('City','month').agg({'AverageTemperature':'avg',\n",
    "                                                 'AverageTemperatureUncertainty':'avg'})\n",
    "\n",
    "# clean up table\n",
    "temperature_avg=temperature_avg.select(\"city\",\n",
    "                               \"month\",\n",
    "                               col(\"avg(AverageTemperature)\").alias(\"avg_temp\"),\n",
    "                               col(\"avg(AverageTemperatureUncertainty)\").alias(\"avg_temp_uncertainty\")).drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+------------------+--------------------+\n",
      "|      city|month|          avg_temp|avg_temp_uncertainty|\n",
      "+----------+-----+------------------+--------------------+\n",
      "|  BELLEVUE|    6|12.756615384615394|   0.700005494505495|\n",
      "|BRIDGEPORT|   12|1.2839808429118775|  1.5540383141762462|\n",
      "|CHARLESTON|   12|11.119011494252877|  1.6366973180076625|\n",
      "+----------+-----+------------------+--------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "temperature_avg.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean airports\n",
    "\n",
    "# only need US airports\n",
    "airport=airport.filter(airport[\"iso_country\"]==\"US\")\\\n",
    ".withColumn('municipality', upper(col('municipality')))\n",
    "\n",
    "# filter for airports \n",
    "airport=airport.where(col(\"type\").isin({\"small_airport\", \"medium_airport\", \"large_airport\"})).drop_duplicates()\n",
    "\n",
    "# parse region for state\n",
    "airport = airport.withColumn('state', split(airport['iso_region'], '-').getItem(1))\\\n",
    ".withColumn(\"elevation_ft\",col(\"elevation_ft\").cast(\"integer\"))\n",
    "\n",
    "# clean up table\n",
    "airport=airport.select(col(\"ident\").alias(\"airport_id\"),\n",
    "                       col(\"municipality\").alias(\"city\"),\n",
    "                       \"state\",\n",
    "                       \"name\",\n",
    "                       \"type\",\n",
    "                       \"elevation_ft\").drop_duplicates()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------+-----+--------------------+-------------+------------+\n",
      "|airport_id|       city|state|                name|         type|elevation_ft|\n",
      "+----------+-----------+-----+--------------------+-------------+------------+\n",
      "|   US-0495|    MILFORD|   IL|Stichnoth RLA Air...|small_airport|         700|\n",
      "|      18XA|     GOLIAD|   TX|Lantana Ridge Air...|small_airport|         250|\n",
      "|      CO92|LAST CHANCE|   CO|Frasier Ranch Air...|small_airport|        5000|\n",
      "+----------+-----------+-----+--------------------+-------------+------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "airport.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean demographics \n",
    "\n",
    "# calculate percentages\n",
    "demographics=demographics.withColumn(\"median_age\",col(\"Median Age\").cast(\"float\"))\\\n",
    ".withColumn(\"pct_male_population\",demographics[\"Male Population\"]/demographics[\"Total Population\"]*100)\\\n",
    ".withColumn(\"pct_female_population\",demographics[\"Female Population\"]/demographics[\"Total Population\"]*100)\\\n",
    ".withColumn(\"pct_foreign_born\",demographics[\"Foreign-born\"]/demographics[\"Total Population\"]*100)\\\n",
    ".withColumn('City', upper(col('City')))\\\n",
    ".withColumn(\"Total Population\",col(\"Total Population\").cast(\"integer\"))\n",
    "\n",
    "# rename fields \n",
    "demographics = demographics.select(\n",
    "    col(\"City\").alias(\"city\"),\n",
    "    col(\"State Code\").alias(\"state\"),\n",
    "    col(\"Total Population\").alias(\"population\"),\n",
    "    \"median_age\",\n",
    "    \"pct_male_population\",\n",
    "    \"pct_female_population\",\n",
    "    \"pct_foreign_born\"\n",
    ").drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-----+----------+----------+-------------------+---------------------+------------------+\n",
      "|         city|state|population|median_age|pct_male_population|pct_female_population|  pct_foreign_born|\n",
      "+-------------+-----+----------+----------+-------------------+---------------------+------------------+\n",
      "|   FORT MYERS|   FL|     74015|      37.3|  49.78720529622374|    50.21279470377627|20.759305546173074|\n",
      "|THOUSAND OAKS|   CA|    129329|      44.8|  50.34678996976702|    49.65321003023297|19.585707768559253|\n",
      "|   COSTA MESA|   CA|    113186|      34.8| 52.212287738766285|    47.78771226123372| 23.54089728411641|\n",
      "+-------------+-----+----------+----------+-------------------+---------------------+------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "demographics.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean immigration data\n",
    "\n",
    "# only need air arivals i94mode=1\n",
    "immigration=immigration.filter(immigration[\"i94mode\"]==1)\\\n",
    ".filter(immigration.i94res.isNotNull())\\\n",
    ".filter(immigration.i94port.isNotNull())\\\n",
    ".withColumn(\"I94MON\",col(\"I94MON\").cast(\"integer\"))\\\n",
    ".withColumn(\"I94RES\",col(\"I94RES\").cast(\"integer\"))\\\n",
    ".withColumn(\"I94YR\",col(\"I94YR\").cast(\"integer\"))\\\n",
    ".withColumn(\"I94BIR\",col(\"I94BIR\").cast(\"integer\"))\\\n",
    ".withColumn(\"count\",col(\"count\").cast(\"integer\"))\\\n",
    ".withColumn(\"I94VISA\",col(\"I94VISA\").cast(\"integer\"))\n",
    "\n",
    "# only take relevant fields \n",
    "immigration = immigration.select(\n",
    "    \"cicid\",\n",
    "    col(\"I94YR\").alias(\"year\"),\n",
    "    col(\"I94MON\").alias(\"month\"),\n",
    "    col(\"I94RES\").alias(\"org_country_code\"),\n",
    "    col(\"I94PORT\").alias(\"dest_city_code\"),\n",
    "    col(\"I94ADDR\").alias(\"dest_state\"),\n",
    "    col(\"I94VISA\").alias(\"visa_type\"),\n",
    "    col(\"I94BIR\").alias(\"age\"),\n",
    "    col(\"GENDER\").alias(\"gender\"),\n",
    "    \"count\"\n",
    ").drop_duplicates()\n",
    "\n",
    "# add dest city name \n",
    "immigration = immigration.withColumn('dest_city', city_codes_udf(\n",
    "    immigration[\"dest_city_code\"]))\n",
    "\n",
    "# add org country \n",
    "immigration = immigration.withColumn('org_country', country_codes_udf(\n",
    "    immigration[\"org_country_code\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aggregate immigration table \n",
    "immigration_ag=immigration.groupBy('year','month', \n",
    "                                  'dest_city_code',\n",
    "                                   'dest_state','age',\n",
    "                                   'visa_type','gender',\n",
    "                                   'dest_city', 'org_country'\n",
    "                                  ).agg({'count':'sum'})\\\n",
    ".withColumnRenamed(\"sum(count)\", \"count\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+--------------+----------+---+---------+------+-----------+-----------+-----+\n",
      "|year|month|dest_city_code|dest_state|age|visa_type|gender|  dest_city|org_country|count|\n",
      "+----+-----+--------------+----------+---+---------+------+-----------+-----------+-----+\n",
      "|2016|    6|           LOS|        CA| 32|        2|     M|LOS ANGELES|    HUNGARY|    7|\n",
      "|2016|    6|           LVG|        NV| 37|        2|     M|  LAS VEGAS|    IRELAND|   12|\n",
      "|2016|    6|           HHW|        HI| 62|        2|     M|   HONOLULU|  AUSTRALIA|   74|\n",
      "+----+-----+--------------+----------+---+---------+------+-----------+-----------+-----+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "immigration_ag.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Define the Data Model\n",
    "#### 3.1 Conceptual Data Model\n",
    "The star schema was chosen because of its simplicity and the flexibility for analysis. It lso allows for minimizing the transformations needed for the dimension tables.\n",
    "\n",
    "**Schema**\n",
    "##### Dimension Tables\n",
    "1. Temperature\n",
    "    1. city\n",
    "    1. month\n",
    "    1. avg_temp\n",
    "    1. avg_temp_uncertainty\n",
    "1. Airport\n",
    "    1. airport_id\n",
    "    1. city\n",
    "    1. state\n",
    "    1. name\n",
    "    1. type\n",
    "    1. elevation_ft\n",
    "1. Demographics \n",
    "    1. city\n",
    "    1. state\n",
    "    1. population\n",
    "    1. median_age\n",
    "    1. pct_male_population\n",
    "    1. pct_female_population\n",
    "    1. pct_foreign_born\n",
    "1. Immigration\n",
    "    1. year\n",
    "    1. month\n",
    "    1. dest_city_code\n",
    "    1. dest_state\n",
    "    1. age\n",
    "    1. visa_type\n",
    "    1. gender\n",
    "    1. dest_city\n",
    "    1. org_country\n",
    "    1. count\n",
    "  \n",
    "##### Fact Table\n",
    "1. Fact\n",
    "    1. year\n",
    "    1. month\n",
    "    1. dest_city\n",
    "    1. dest_state\n",
    "    1. org_country\n",
    "    1. avg_temp\n",
    "    1. num_airports\n",
    "    1. population\n",
    "    1. pct_foreign_born\n",
    "    1. imigration_count\n",
    "\n",
    "\n",
    "#### 3.2 Mapping Out Data Pipelines\n",
    "Data pipeline steps for data model \n",
    "1. Using the cleaned and minimally transformed data generate the dimension tables as DataFrames\n",
    "1. Generate the Fact table using Spark SQL to join the dimension tables\n",
    "1. Write fact table to parquet files as this is the only significant transformation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Run Pipelines to Model the Data \n",
    "#### 4.1 Create the data model\n",
    "Build the data pipelines to create the data model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create spark sql views \n",
    "\n",
    "temperature_avg.createOrReplaceTempView(\"temperature\")\n",
    "airport.createOrReplaceTempView(\"airport\")\n",
    "demographics.createOrReplaceTempView(\"demographics\")\n",
    "immigration_ag.createOrReplaceTempView(\"immigration\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fact=spark.sql(\"\"\"\n",
    "SELECT \n",
    "    i.year, \n",
    "    i.month, \n",
    "    i.dest_city, \n",
    "    i.dest_state,\n",
    "    i.org_country,\n",
    "    t.avg_temp,\n",
    "    a.num_airports,\n",
    "    d.population,\n",
    "    d.pct_foreign_born,\n",
    "    SUM(i.count) as imigration_count\n",
    "   \n",
    "FROM immigration i\n",
    "JOIN temperature t ON i.dest_city=t.city AND i.month=t.month\n",
    "JOIN (\n",
    "    select city, state, COUNT(airport_id) as num_airports \n",
    "    FROM airport \n",
    "    GROUP BY city, state\n",
    "    ) a ON i.dest_city=a.city AND i.dest_state = a.state\n",
    "JOIN demographics d ON i.dest_city=d.city AND i.dest_state = d.state\n",
    "\n",
    "GROUP BY \n",
    "    i.year, \n",
    "    i.month, \n",
    "    i.dest_city, \n",
    "    i.dest_state,\n",
    "    i.org_country,\n",
    "    t.avg_temp,\n",
    "    d.population,\n",
    "    d.pct_foreign_born ,\n",
    "    a.num_airports\n",
    "\n",
    "ORDER BY \n",
    "    i.dest_city, i.org_country\n",
    "\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+-----------+----------+-----------+-----------------+------------+----------+------------------+----------------+\n",
      "|year|month|  dest_city|dest_state|org_country|         avg_temp|num_airports|population|  pct_foreign_born|imigration_count|\n",
      "+----+-----+-----------+----------+-----------+-----------------+------------+----------+------------------+----------------+\n",
      "|2016|    6|ALBUQUERQUE|        NM|     FRANCE|20.76131088082901|           3|    559131| 10.40900969540233|               1|\n",
      "|2016|    6|  ANCHORAGE|        AK| ARGENTINA |9.911816666666668|          10|    298695|11.134434791342338|               2|\n",
      "|2016|    6|  ANCHORAGE|        AK|  AUSTRALIA|9.911816666666668|          10|    298695|11.134434791342338|             352|\n",
      "|2016|    6|  ANCHORAGE|        AK|    AUSTRIA|9.911816666666668|          10|    298695|11.134434791342338|              79|\n",
      "|2016|    6|  ANCHORAGE|        AK|    BELARUS|9.911816666666668|          10|    298695|11.134434791342338|               1|\n",
      "|2016|    6|  ANCHORAGE|        AK|    BELGIUM|9.911816666666668|          10|    298695|11.134434791342338|              80|\n",
      "|2016|    6|  ANCHORAGE|        AK|     BRAZIL|9.911816666666668|          10|    298695|11.134434791342338|              28|\n",
      "|2016|    6|  ANCHORAGE|        AK|   BULGARIA|9.911816666666668|          10|    298695|11.134434791342338|               6|\n",
      "|2016|    6|  ANCHORAGE|        AK|      CHILE|9.911816666666668|          10|    298695|11.134434791342338|               4|\n",
      "|2016|    6|  ANCHORAGE|        AK| CHINA, PRC|9.911816666666668|          10|    298695|11.134434791342338|             115|\n",
      "+----+-----+-----------+----------+-----------+-----------------+------------+----------+------------------+----------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fact.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- year: integer (nullable = true)\n",
      " |-- month: integer (nullable = true)\n",
      " |-- dest_city: string (nullable = true)\n",
      " |-- dest_state: string (nullable = true)\n",
      " |-- org_country: string (nullable = true)\n",
      " |-- avg_temp: double (nullable = true)\n",
      " |-- num_airports: long (nullable = false)\n",
      " |-- population: integer (nullable = true)\n",
      " |-- pct_foreign_born: double (nullable = true)\n",
      " |-- imigration_count: long (nullable = true)\n",
      "\n",
      "root\n",
      " |-- year: integer (nullable = true)\n",
      " |-- month: integer (nullable = true)\n",
      " |-- dest_city_code: string (nullable = true)\n",
      " |-- dest_state: string (nullable = true)\n",
      " |-- age: integer (nullable = true)\n",
      " |-- visa_type: integer (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- dest_city: string (nullable = true)\n",
      " |-- org_country: string (nullable = true)\n",
      " |-- count: long (nullable = true)\n",
      "\n",
      "root\n",
      " |-- city: string (nullable = true)\n",
      " |-- month: integer (nullable = true)\n",
      " |-- avg_temp: double (nullable = true)\n",
      " |-- avg_temp_uncertainty: double (nullable = true)\n",
      "\n",
      "root\n",
      " |-- airport_id: string (nullable = true)\n",
      " |-- city: string (nullable = true)\n",
      " |-- state: string (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- type: string (nullable = true)\n",
      " |-- elevation_ft: integer (nullable = true)\n",
      "\n",
      "root\n",
      " |-- city: string (nullable = true)\n",
      " |-- state: string (nullable = true)\n",
      " |-- population: integer (nullable = true)\n",
      " |-- median_age: float (nullable = true)\n",
      " |-- pct_male_population: double (nullable = true)\n",
      " |-- pct_female_population: double (nullable = true)\n",
      " |-- pct_foreign_born: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fact.printSchema()\n",
    "immigration_ag.printSchema()\n",
    "temperature_avg.printSchema()\n",
    "airport.printSchema()\n",
    "demographics.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing 3258 rows to parquet\n"
     ]
    }
   ],
   "source": [
    "# write fact table to parquet\n",
    "print('Writing {} rows to parquet'.format(fact.count()))\n",
    "fact.write.partitionBy('dest_city','dest_state').option('compression','snappy')\\\n",
    ".parquet(\"data_tables/fact\",mode='overwrite')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2 Data Quality Checks\n",
    "Explain the data quality checks you'll perform to ensure the pipeline ran as expected. These could include:\n",
    " * Integrity constraints on the relational database (e.g., unique key, data type, etc.)\n",
    " * Unit tests for the scripts to ensure they are doing the right thing\n",
    " * Source/Count checks to ensure completeness\n",
    " \n",
    "Run Quality Checks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Check for null values in fact table\n",
    "1. Make sure fact table sums correctly compared to raw data\n",
    "1. Confirm shape of fact table "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+-----------+---------+--------+------------+----------+----------------+\n",
      "| year|month|org_country|dest_city|avg_temp|num_airports|population|pct_foreign_born|\n",
      "+-----+-----+-----------+---------+--------+------------+----------+----------------+\n",
      "|false|false|      false|    false|   false|       false|     false|           false|\n",
      "+-----+-----+-----------+---------+--------+------------+----------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# check for null values in the fact table \n",
    "fact.select(isnull('year').alias('year'),\n",
    "            isnull('month').alias('month'),\n",
    "            isnull('org_country').alias('org_country'),\n",
    "            isnull('dest_city').alias('dest_city'),\n",
    "            isnull('avg_temp').alias('avg_temp'),\n",
    "            isnull('num_airports').alias('num_airports'),\n",
    "            isnull('population').alias('population'),\n",
    "            isnull('pct_foreign_born').alias('pct_foreign_born')\n",
    "           ).dropDuplicates().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+\n",
      "|dest_city|sum(count)|\n",
      "+---------+----------+\n",
      "| NEW YORK|    443474|\n",
      "+---------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test1 = immigration.select(\n",
    "    'count', 'dest_city').filter(\n",
    "    immigration['dest_city']=='NEW YORK').filter(\n",
    "    immigration['dest_state']=='NY').filter(\n",
    "    immigration['month']==6)\n",
    "test1=test1.groupBy('dest_city').agg({'count':'sum'})\n",
    "\n",
    "test1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------------------+\n",
      "|dest_city|sum(imigration_count)|\n",
      "+---------+---------------------+\n",
      "| NEW YORK|               443474|\n",
      "+---------+---------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# test2 should match test1 \n",
    "test2 = fact.select(\n",
    "    'dest_city', 'imigration_count').filter(\n",
    "    fact['dest_city']=='NEW YORK').filter(\n",
    "    fact['dest_state']=='NY').filter(\n",
    "    fact['month']=='6')\n",
    "test2=test2.groupBy('dest_city').agg({'imigration_count':'sum'})\n",
    "\n",
    "test2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+\n",
      "|total_count|\n",
      "+-----------+\n",
      "|    1680508|\n",
      "+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Count the total count from the fact table\n",
    "fact.select(sum('imigration_count').alias('total_count')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of records: 3258\n",
      "Columns: 10\n"
     ]
    }
   ],
   "source": [
    "# Check table format and rows are correct \n",
    "print(\"Number of records: {r}\\nColumns: {c}\".format(\n",
    "    r=fact.count(),c=len(fact.columns)\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3 Data dictionary \n",
    "\n",
    "**fact**\n",
    " - year(Integer): Calendar year YYYY\n",
    " - month(Integer): Calendar month \n",
    " - dest_city(String): Name of city of arrival\n",
    " - dest_state(String): State of arrival abbriviation (e.x. NY)\n",
    " - org_country(String): Name of country of origin \n",
    " - avg_temp(Double): Average monthly temperature of the city of arrvial\n",
    " - num_airport(long): Number of airports for the city of arrvial\n",
    " - population(Integer): Total popultaion of the city of arrvial\n",
    " - pct_foreign_born(Double): Percentage of total population that is foreign born in the city of arrvial\n",
    " - imigration_count(Long): Number of internatonal arrvials \n",
    "  \n",
    "**immigration_ag**\n",
    " - year(Integer): Calendar year YYYY\n",
    " - month(Integer): Calendar month\n",
    " - dest_city_code(String): Code for city of arrival\n",
    " - dest_state(String): State of arrival abbriviation (e.x. NY)\n",
    " - age(Integer): Age of person\n",
    " - visa_type(Integer): Visa type listed on I94 (1: Business, 2: Pleasure, 3: Student)\n",
    " - gender(String): Gender of person listed on I94 (M: Male, F:Female)\n",
    " - dest_city(String): Name of city of arrival\n",
    " - org_country(String): Name of country of origin \n",
    " - count(Long): Number of internatonal arrvials \n",
    "  \n",
    "**temperature_avg**\n",
    " - city(String): Name of U.S. City \n",
    " - month(Integer): Calendar month\n",
    " - avg_temp(Double): Average temperature in degrees Celsius\n",
    " - avg_temp_uncertainty(Double): Average temperature uncertanty in degrees Celsius\n",
    "  \n",
    "**airport**\n",
    " - airport_id(String): Airport ID code\n",
    " - city(String): Name of city the airport services \n",
    " - state(String): State abbriviation (e.x. NY) for airport\n",
    " - name(String): Airport name\n",
    " - type(String): Type of airport (e.x. small_airport)\n",
    " - elevation_ft(Integer): Elevation of airport in feet\n",
    "\n",
    "**demographics**\n",
    " - city(String): City name\n",
    " - state(String): State abbriviation (e.x. NY) for airport\n",
    " - population(Integer): Total popultaion of the city\n",
    " - median_age(Float): Median age of population in city\n",
    " - pct_male_population(Double): Percent male of population in city\n",
    " - pct_female_population(Double): Percent female of population in city\n",
    " - pct_foreign_born(Double): Percent foreign-born of population in city"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 5: Complete Project Write Up\n",
    "Given the size of the data and the frequency of updates, Apache Spark was chosen as the logical tool to processing the data. The fact table generated by Spark SQL is written back to the data lake as parquet files partitioned by city and state. The data should be updated at most monthly, to match the level of aggregation used. \n",
    "\n",
    "Under different scenarios the project would look different. \n",
    " - If the data was increased by 100x, the process would remain similar but should leverage Apache Hadoop to distribute the processing for improved performance \n",
    " - If the data needed to updated and reported daily, Airflow should be used to schedule and run the data pipeline. This could be scheduled to ensure that the data is available for the dashboard reporting time and any issues in the process could be appropriately identified and handled. \n",
    " - If the data needed to be accessed by 100+ people, migrating to a data warehouse design on a cloud hosted database (e.g. AWS Redshift) would be more appropriate. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
